{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "from ultralytics import YOLO\n",
    "\n",
    "#mange images,tensor,numpy\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#manage file,path\n",
    "import glob\n",
    "import os\n",
    "\n",
    "#etc\n",
    "import tqdm\n",
    "\n",
    "import wandb\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=glob.glob(\"/Users/kunkerdthaisong/nectec/gov_doc_ocr/thai_gov_ocr.v1i.yolov8/train/images/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/kunkerdthaisong/nectec/gov_doc_ocr/wandb/run-20240801_163041-x8y41kr1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/my_lab/gov_doc_ocr/runs/x8y41kr1' target=\"_blank\">comic-star-1</a></strong> to <a href='https://wandb.ai/my_lab/gov_doc_ocr' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/my_lab/gov_doc_ocr' target=\"_blank\">https://wandb.ai/my_lab/gov_doc_ocr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/my_lab/gov_doc_ocr/runs/x8y41kr1' target=\"_blank\">https://wandb.ai/my_lab/gov_doc_ocr/runs/x8y41kr1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.login()\n",
    "\n",
    "\n",
    "run = wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"gov_doc_ocr\",\n",
    "    config={\"task\": \"inference\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=YOLO(\"/Users/kunkerdthaisong/nectec/gov_doc_ocr/runs/detect/train9/weights/best.pt\") #yolo s jaa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 -s, 1 -s, 153.3ms\n",
      "Speed: 18.4ms preprocess, 153.3ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 -, 1 -s, 126.6ms\n",
      "Speed: 1.2ms preprocess, 126.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 -s, 1 -s, 114.8ms\n",
      "Speed: 1.1ms preprocess, 114.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 -, 1 -s, 165.5ms\n",
      "Speed: 0.9ms preprocess, 165.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 -s, 1 -s, 116.8ms\n",
      "Speed: 0.9ms preprocess, 116.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 -s, 1 -s, 127.4ms\n",
      "Speed: 1.1ms preprocess, 127.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 -s, 1 -s, 121.2ms\n",
      "Speed: 1.2ms preprocess, 121.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 -s, 1 -s, 126.3ms\n",
      "Speed: 1.1ms preprocess, 126.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 -s, 1 -s, 116.9ms\n",
      "Speed: 0.8ms preprocess, 116.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 -s, 2 -ss, 116.0ms\n",
      "Speed: 0.9ms preprocess, 116.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 -, 1 -s, 113.2ms\n",
      "Speed: 1.1ms preprocess, 113.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 -s, 114.5ms\n",
      "Speed: 0.9ms preprocess, 114.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 -s, 1 -s, 110.4ms\n",
      "Speed: 0.9ms preprocess, 110.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 -s, 1 -s, 117.9ms\n",
      "Speed: 0.9ms preprocess, 117.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 -s, 1 -s, 114.0ms\n",
      "Speed: 0.9ms preprocess, 114.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 -s, 1 -s, 119.7ms\n",
      "Speed: 1.2ms preprocess, 119.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 -s, 1 -s, 117.5ms\n",
      "Speed: 0.9ms preprocess, 117.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 -s, 1 -s, 130.9ms\n",
      "Speed: 1.2ms preprocess, 130.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 -s, 1 -s, 121.7ms\n",
      "Speed: 1.0ms preprocess, 121.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 -s, 111.4ms\n",
      "Speed: 1.1ms preprocess, 111.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 -, 1 -s, 126.5ms\n",
      "Speed: 0.9ms preprocess, 126.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 -s, 1 -s, 124.2ms\n",
      "Speed: 0.9ms preprocess, 124.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 -, 1 -s, 130.8ms\n",
      "Speed: 1.0ms preprocess, 130.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 -s, 1 -s, 119.3ms\n",
      "Speed: 1.2ms preprocess, 119.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 -, 1 -s, 117.1ms\n",
      "Speed: 1.0ms preprocess, 117.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 -, 1 -s, 119.7ms\n",
      "Speed: 0.9ms preprocess, 119.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 -, 1 -s, 118.5ms\n",
      "Speed: 1.4ms preprocess, 118.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 -s, 1 -s, 115.8ms\n",
      "Speed: 1.0ms preprocess, 115.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 -s, 1 -s, 113.7ms\n",
      "Speed: 1.0ms preprocess, 113.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 -s, 1 -s, 115.8ms\n",
      "Speed: 0.8ms preprocess, 115.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 -s, 1 -s, 113.0ms\n",
      "Speed: 0.9ms preprocess, 113.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 -s, 1 -s, 115.4ms\n",
      "Speed: 1.0ms preprocess, 115.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "for i in ls:\n",
    "    img=cv2.imread(i)\n",
    "    name=os.path.basename(i)\n",
    "    result=model.predict(img,conf=0.5,augment=False)\n",
    "\n",
    "    boxes = []\n",
    "    labels = []\n",
    "    scores = []\n",
    "\n",
    "    for i in result:\n",
    "        for b, l, s in zip(i.boxes.xyxy.tolist(), i.boxes.cls.int().tolist(), i.boxes.conf.tolist()):\n",
    "\n",
    "            boxes.append([round(e) for e in b])\n",
    "\n",
    "            #boxes.append(b)\n",
    "            labels.append(l)\n",
    "            scores.append(s)\n",
    "    color = (0, 255, 0)  # Green\n",
    "\n",
    "    # Define the thickness of the bounding box lines\n",
    "    thickness = 2\n",
    "\n",
    "    # Draw each bounding box on the image\n",
    "    n=f\"/Users/kunkerdthaisong/nectec/gov_doc_ocr/saved/{name.split(\".\")[0]}\"\n",
    "    os.makedirs(n,exist_ok=True)\n",
    "    c=0\n",
    "    for bbox in boxes:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        # Draw the rectangle on the image\n",
    "        #cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness)\n",
    "        cropped_img = img[y1:y2, x1:x2]\n",
    "\n",
    "        # Generate a unique name for the cropped image\n",
    "        cropped_img_name = f'{n}/_crop_{c}.png'\n",
    "\n",
    "        # Save the cropped image\n",
    "        cv2.imwrite(cropped_img_name, cropped_img)\n",
    "        c+=1\n",
    "\n",
    "\n",
    "    cv2.imwrite(f'/Users/kunkerdthaisong/nectec/gov_doc_ocr/saved/{name}', img)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=YOLO(\"/Users/kunkerdthaisong/nectec/gov_doc_ocr/best.pt\") #yolo s jaa\n",
    "img=cv2.imread(\"/Users/kunkerdthaisong/nectec/gov_doc_ocr/thai_gov_ocr.v1i.yolov8/train/images/-2_png.rf.027aebf21670395f39f6c5a4572e7493.jpg\")\n",
    "result=model.predict(img,conf=0.8,augment=False)\n",
    "\n",
    "boxes = []\n",
    "labels = []\n",
    "scores = []\n",
    "\n",
    "for i in result:\n",
    "    for b, l, s in zip(i.boxes.xyxy.tolist(), i.boxes.cls.int().tolist(), i.boxes.conf.tolist()):\n",
    "\n",
    "        boxes.append([round(e) for e in b])\n",
    "\n",
    "        #boxes.append(b)\n",
    "        labels.append(l)\n",
    "        scores.append(s)\n",
    "color = (0, 255, 0)  # Green\n",
    "\n",
    "# Define the thickness of the bounding box lines\n",
    "thickness = 2\n",
    "\n",
    "# Draw each bounding box on the image\n",
    "for bbox in boxes:\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    # Draw the rectangle on the image\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "\n",
    "cv2.imwrite('image_with_bounding_boxes.jpg', img)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
